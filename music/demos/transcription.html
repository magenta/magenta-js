<!-- Copyright 2018 Google Inc. All Rights Reserved.
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
    http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================-->
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1, user-scalable=yes">
  <link rel="stylesheet" href="./style.css">
  <title>Transcription</title>
</head>
<body>
  <h1>Onsets and Frames</h1>
  <p><code><a href="https://g.co/magenta/onsets-frames">Onsets and Frames</a></code>
    is a deep neural network that transcribes audio of piano performances to
    <code>NoteSequences</code>/<code>MIDI</code>.
  </p>
  <p>Below we verify that the model properly transcribes a mel spectrogram to match the output
    of the Python TensorFlow implementation. We found it is necessary to process the convolution
    in batches for longer inputs to avoid a GPU timeout enforced in Chrome, and we verify that
    the transcription works properly with different batch sizes that exercise various edge cases.
  </p>

  <h2>From <a href="https://librosa.github.io/librosa/generated/librosa.feature.melspectrogram.html" target="_blank">Mel Spectrogram</a> (250 frames / 8 seconds)</h2>
  <section>
    <p><b>Original Audio</b><br><audio controls><source type="audio/wav" src="https://storage.googleapis.com/magentadata/js/checkpoints/transcription/onsets_frames_htk0/MAPS_MUS-mz_331_3_ENSTDkCl-250frames.wav"></audio></p>
    <p><b>Expected Transcription:</b> <code id="expected-ns">Loading...</code></p>
  </section>

  <section>
    <h3>Audio</h3>
    <p><b>Actual Transcription:</b> <code id="audio-results">Loading...</code></p>
    <p><b>Match:</b> <code id="audio-match">Loading...</code></p>
    <p><b>It Took:</b> <code id="audio-time">Loading...</code></p>
  </section>

  <section>
    <h3>Batch Length 250 / Batch Size 1</h3>
    <p><b>Actual Transcription:</b> <code id="250-results">Loading...</code></p>
    <p><b>Match:</b> <code id="250-match">Loading...</code></p>
    <p><b>It Took:</b> <code id="250-time">Loading...</code></p>
  </section>

  <section>
    <h3>Batch Length 150 / Batch Size 2</h3>
    <p><b>Actual Transcription:</b> <code id="150-results">Loading...</code></p>
    <p><b>Match:</b> <code id="150-match">Loading...</code></p>
    <p><b>It Took:</b> <code id="150-time">Loading...</code></p>
  </section>

  <section>
    <h3>Batch Length 80 / Batch Size 4</h3>
    <p><b>Actual Transcription:</b> <code id="80-results">Loading...</code></p>
    <p><b>Match:</b> <code id="80-match">Loading...</code></p>
    <p><b>It Took:</b> <code id="80-time">Loading...</code></p>
  </section>

  <section>
      <h3>Batch Length 62 / Batch Size 4</h3>
      <p><b>Actual Transcription:</b> <code id="62-results">Loading...</code></p>
      <p><b>Match:</b> <code id="62-match">Loading...</code></p>
      <p><b>It Took:</b> <code id="62-time">Loading...</code></p>
  </section>

  <section>
      <h3>Batch Length 50 / Batch Size 5</h3>
      <p><b>Actual Transcription:</b> <code id="50-results">Loading...</code></p>
      <p><b>Match:</b> <code id="50-match">Loading...</code></p>
      <p><b>It Took:</b> <code id="50-time">Loading...</code></p>
    </section>

  <section>
    <p><b>Total Leaked Memory:</b> <code id="leaked-memory">Loading...</code></b></p>
  </section>

  <script src="transcription_bundle.js"></script>
</body>
</html>
